{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-Commerce Medallion Pipeline\n",
    "## Bronze → Silver → Gold\n",
    "\n",
    "This notebook processes raw e-commerce data through the Medallion architecture:\n",
    "- **Bronze**: Raw data ingestion (as-is from source)\n",
    "- **Silver**: Cleaned and standardized data\n",
    "- **Gold**: Joined table for analytics (Customer 360° View)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "BASE_PATH = \"/Volumes/SSD-CRUCIAL/Medallion/Local_Lakehouse_2\"\n",
    "BRONZE = f\"{BASE_PATH}/bronze\"\n",
    "SILVER = f\"{BASE_PATH}/silver\"\n",
    "GOLD = f\"{BASE_PATH}/gold\"\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(BRONZE, exist_ok=True)\n",
    "os.makedirs(SILVER, exist_ok=True)\n",
    "os.makedirs(GOLD, exist_ok=True)\n",
    "\n",
    "print(\"Directories ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(date_str):\n",
    "    \"\"\"\n",
    "    Parse multiple date formats into standardized YYYY-MM-DD.\n",
    "    Handles: 2022/07/15, 15-07-2022, 20220719, etc.\n",
    "    \"\"\"\n",
    "    if pd.isna(date_str) or str(date_str).lower() in ['nan', 'n/a', 'na', '']:\n",
    "        return ''\n",
    "    date_str = str(date_str).strip()\n",
    "    \n",
    "    formats = [\n",
    "        '%Y-%m-%d', '%Y/%m/%d', '%d-%m-%Y', '%d/%m/%Y', '%Y%m%d'\n",
    "    ]\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=fmt).strftime('%Y-%m-%d')\n",
    "        except:\n",
    "            continue\n",
    "    try:\n",
    "        return pd.to_datetime(date_str).strftime('%Y-%m-%d')\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "\n",
    "def validate_email(email):\n",
    "    \"\"\"\n",
    "    Validate email format. Returns lowercase email if valid, None if invalid.\n",
    "    \"\"\"\n",
    "    if pd.isna(email):\n",
    "        return None\n",
    "    email = str(email).lower().strip()\n",
    "    pattern = r'^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$'\n",
    "    if re.match(pattern, email):\n",
    "        return email\n",
    "    return None\n",
    "\n",
    "\n",
    "def clean_gender(g):\n",
    "    \"\"\"\n",
    "    Standardize gender to Male/Female.\n",
    "    \"\"\"\n",
    "    if pd.isna(g):\n",
    "        return None\n",
    "    g = str(g).lower().strip()\n",
    "    if g in ['m', 'male']:\n",
    "        return 'Male'\n",
    "    if g in ['f', 'female']:\n",
    "        return 'Female'\n",
    "    return None\n",
    "\n",
    "\n",
    "print(\"Helper functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# BRONZE LAYER - Raw Data\n",
    "Copy raw files to bronze folder (no transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source path for raw data\n",
    "SOURCE_PATH = \"/Volumes/SSD-CRUCIAL/Medallion/DATASET-2\"\n",
    "\n",
    "# Copy raw files to bronze\n",
    "import shutil\n",
    "\n",
    "files = ['customers.csv', 'orders.csv', 'payments.csv', 'support_tickets.csv', 'web_activities.csv']\n",
    "\n",
    "for f in files:\n",
    "    shutil.copy(f\"{SOURCE_PATH}/{f}\", f\"{BRONZE}/{f}\")\n",
    "    print(f\"✓ Copied {f} to bronze/\")\n",
    "\n",
    "print(\"\\nBronze layer complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SILVER LAYER - Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clean customers.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "df = pd.read_csv(f\"{BRONZE}/customers.csv\")\n",
    "print(\"=== RAW CUSTOMERS ===\")\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean customers\n",
    "df = pd.read_csv(f\"{BRONZE}/customers.csv\")\n",
    "\n",
    "# 1. Rename columns\n",
    "df = df.rename(columns={\n",
    "    'customer_id': 'CustomerID',\n",
    "    'name': 'Name',\n",
    "    'EMAIL': 'Email',\n",
    "    'gender': 'Gender',\n",
    "    'dob': 'DOB',\n",
    "    'location': 'City'\n",
    "})\n",
    "\n",
    "# 2. Clean Name (Title Case)\n",
    "df['Name'] = df['Name'].apply(\n",
    "    lambda x: str(x).strip().title() if pd.notna(x) else None\n",
    ")\n",
    "\n",
    "# 3. Validate Email\n",
    "df['Email'] = df['Email'].apply(validate_email)\n",
    "\n",
    "# 4. Standardize Gender (Male/Female)\n",
    "df['Gender'] = df['Gender'].apply(clean_gender)\n",
    "\n",
    "# 5. Standardize DOB (YYYY-MM-DD)\n",
    "def clean_dob(dob):\n",
    "    if pd.isna(dob):\n",
    "        return None\n",
    "    dob_str = str(dob).strip()\n",
    "    if dob_str.lower() in ['not available', 'n/a', 'na', '']:\n",
    "        return None\n",
    "    result = clean_date(dob_str)\n",
    "    return result if result else None\n",
    "\n",
    "df['DOB'] = df['DOB'].apply(clean_dob)\n",
    "\n",
    "# 6. Clean City (Title Case)\n",
    "df['City'] = df['City'].apply(\n",
    "    lambda x: str(x).strip().title() if pd.notna(x) else None\n",
    ")\n",
    "\n",
    "# Save to silver\n",
    "df.to_csv(f\"{SILVER}/customers_clean.csv\", index=False)\n",
    "\n",
    "print(\"=== CLEANED CUSTOMERS ===\")\n",
    "print(df.to_string())\n",
    "print(f\"\\n✓ Saved to: silver/customers_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean orders.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "df = pd.read_csv(f\"{BRONZE}/orders.csv\")\n",
    "print(\"=== RAW ORDERS ===\")\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean orders\n",
    "df = pd.read_csv(f\"{BRONZE}/orders.csv\")\n",
    "\n",
    "# 1. Rename columns\n",
    "df = df.rename(columns={\n",
    "    'order_id': 'OrderID',\n",
    "    'customer_id': 'CustomerID',\n",
    "    'order_date': 'OrderDate',\n",
    "    'amount': 'Amount',\n",
    "    'status': 'Status'\n",
    "})\n",
    "\n",
    "# 2. Standardize OrderDate (YYYY-MM-DD)\n",
    "df['OrderDate'] = df['OrderDate'].apply(clean_date)\n",
    "\n",
    "# 3. Clean Amount (plain number, 2 decimals, NaN → 0.00)\n",
    "df['Amount'] = df['Amount'].fillna(0.0).round(2)\n",
    "\n",
    "# 4. Standardize Status (Title Case)\n",
    "df['Status'] = df['Status'].apply(\n",
    "    lambda x: str(x).strip().title() if pd.notna(x) else None\n",
    ")\n",
    "\n",
    "# Save to silver\n",
    "df.to_csv(f\"{SILVER}/orders_clean.csv\", index=False)\n",
    "\n",
    "print(\"=== CLEANED ORDERS ===\")\n",
    "print(df.to_string())\n",
    "print(f\"\\n✓ Saved to: silver/orders_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean payments.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "df = pd.read_csv(f\"{BRONZE}/payments.csv\")\n",
    "print(\"=== RAW PAYMENTS ===\")\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean payments\n",
    "df = pd.read_csv(f\"{BRONZE}/payments.csv\")\n",
    "\n",
    "# 1. Rename columns\n",
    "df = df.rename(columns={\n",
    "    'payment_id': 'PaymentID',\n",
    "    'customer_id': 'CustomerID',\n",
    "    'payment_date': 'PaymentDate',\n",
    "    'payment_method': 'PaymentMethod',\n",
    "    'payment_status': 'PaymentStatus',\n",
    "    'amount': 'Amount'\n",
    "})\n",
    "\n",
    "# 2. Standardize PaymentDate (YYYY-MM-DD), NaN → blank\n",
    "df['PaymentDate'] = df['PaymentDate'].apply(clean_date)\n",
    "\n",
    "# 3. Standardize PaymentMethod (Title Case, merge creditcard → Credit Card)\n",
    "def clean_payment_method(method):\n",
    "    if pd.isna(method):\n",
    "        return None\n",
    "    method = str(method).strip().lower()\n",
    "    if method in ['creditcard', 'credit card']:\n",
    "        return 'Credit Card'\n",
    "    return method.title()\n",
    "\n",
    "df['PaymentMethod'] = df['PaymentMethod'].apply(clean_payment_method)\n",
    "\n",
    "# 4. Standardize PaymentStatus (Title Case)\n",
    "df['PaymentStatus'] = df['PaymentStatus'].apply(\n",
    "    lambda x: str(x).strip().title() if pd.notna(x) else None\n",
    ")\n",
    "\n",
    "# 5. Amount (2 decimal places, NaN → 0.00)\n",
    "df['Amount'] = df['Amount'].fillna(0.0).round(2)\n",
    "\n",
    "# Save to silver\n",
    "df.to_csv(f\"{SILVER}/payments_clean.csv\", index=False)\n",
    "\n",
    "print(\"=== CLEANED PAYMENTS ===\")\n",
    "print(df.to_string())\n",
    "print(f\"\\n✓ Saved to: silver/payments_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean support_tickets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "df = pd.read_csv(f\"{BRONZE}/support_tickets.csv\")\n",
    "print(\"=== RAW SUPPORT TICKETS ===\")\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean support_tickets\n",
    "df = pd.read_csv(f\"{BRONZE}/support_tickets.csv\")\n",
    "\n",
    "# 1. Rename columns\n",
    "df = df.rename(columns={\n",
    "    'ticket_id': 'TicketID',\n",
    "    'customer_id': 'CustomerID',\n",
    "    'issue_type': 'IssueType',\n",
    "    'ticket_date': 'TicketDate',\n",
    "    'resolution_status': 'ResolutionStatus'\n",
    "})\n",
    "\n",
    "# 2. Standardize TicketDate (YYYY-MM-DD), NaN → blank\n",
    "df['TicketDate'] = df['TicketDate'].apply(clean_date)\n",
    "\n",
    "# 3. Standardize IssueType (Title Case), NaN → blank\n",
    "def clean_issue_type(issue):\n",
    "    if pd.isna(issue) or str(issue).lower() in ['nan', 'na', '']:\n",
    "        return ''\n",
    "    return str(issue).strip().title()\n",
    "\n",
    "df['IssueType'] = df['IssueType'].apply(clean_issue_type)\n",
    "\n",
    "# 4. Standardize ResolutionStatus (Title Case), NaN → blank\n",
    "def clean_status(status):\n",
    "    if pd.isna(status) or str(status).lower() in ['nan', 'na', '']:\n",
    "        return ''\n",
    "    return str(status).strip().title()\n",
    "\n",
    "df['ResolutionStatus'] = df['ResolutionStatus'].apply(clean_status)\n",
    "\n",
    "# Save to silver\n",
    "df.to_csv(f\"{SILVER}/support_tickets_clean.csv\", index=False)\n",
    "\n",
    "print(\"=== CLEANED SUPPORT TICKETS ===\")\n",
    "print(df.to_string())\n",
    "print(f\"\\n✓ Saved to: silver/support_tickets_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clean web_activities.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "df = pd.read_csv(f\"{BRONZE}/web_activities.csv\")\n",
    "print(\"=== RAW WEB ACTIVITIES ===\")\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean web_activities\n",
    "df = pd.read_csv(f\"{BRONZE}/web_activities.csv\")\n",
    "\n",
    "# 1. Rename columns\n",
    "df = df.rename(columns={\n",
    "    'session_id': 'SessionID',\n",
    "    'customer_id': 'CustomerID',\n",
    "    'page_viewed': 'PageViewed',\n",
    "    'session_time': 'SessionTime',\n",
    "    'device_type': 'DeviceType'\n",
    "})\n",
    "\n",
    "# 2. Standardize SessionTime (YYYY-MM-DD)\n",
    "df['SessionTime'] = df['SessionTime'].apply(clean_date)\n",
    "\n",
    "# 3. Standardize PageViewed (lowercase)\n",
    "df['PageViewed'] = df['PageViewed'].apply(\n",
    "    lambda x: str(x).strip().lower() if pd.notna(x) else ''\n",
    ")\n",
    "\n",
    "# 4. Standardize DeviceType (Title Case)\n",
    "df['DeviceType'] = df['DeviceType'].apply(\n",
    "    lambda x: str(x).strip().title() if pd.notna(x) else ''\n",
    ")\n",
    "\n",
    "# Save to silver\n",
    "df.to_csv(f\"{SILVER}/web_activities_clean.csv\", index=False)\n",
    "\n",
    "print(\"=== CLEANED WEB ACTIVITIES ===\")\n",
    "print(df.to_string())\n",
    "print(f\"\\n✓ Saved to: silver/web_activities_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# GOLD LAYER - Join Tables\n",
    "Create Customer 360° View by joining all Silver tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all Silver tables\n",
    "customers = pd.read_csv(f\"{SILVER}/customers_clean.csv\")\n",
    "orders = pd.read_csv(f\"{SILVER}/orders_clean.csv\")\n",
    "payments = pd.read_csv(f\"{SILVER}/payments_clean.csv\")\n",
    "tickets = pd.read_csv(f\"{SILVER}/support_tickets_clean.csv\")\n",
    "web = pd.read_csv(f\"{SILVER}/web_activities_clean.csv\")\n",
    "\n",
    "print(\"=== SILVER TABLES ===\")\n",
    "print(f\"Customers: {len(customers)} rows\")\n",
    "print(f\"Orders: {len(orders)} rows\")\n",
    "print(f\"Payments: {len(payments)} rows\")\n",
    "print(f\"Support Tickets: {len(tickets)} rows\")\n",
    "print(f\"Web Activities: {len(web)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to avoid conflicts\n",
    "orders = orders.rename(columns={'Amount': 'OrderAmount', 'Status': 'OrderStatus'})\n",
    "payments = payments.rename(columns={'Amount': 'PaymentAmount'})\n",
    "\n",
    "# LEFT JOIN all tables on CustomerID\n",
    "# Why LEFT JOIN? Keep all customers even if they have missing data in other tables\n",
    "\n",
    "gold = customers.merge(orders, on='CustomerID', how='left')\n",
    "gold = gold.merge(payments, on='CustomerID', how='left')\n",
    "gold = gold.merge(tickets, on='CustomerID', how='left')\n",
    "gold = gold.merge(web, on='CustomerID', how='left')\n",
    "\n",
    "print(f\"\\n=== GOLD TABLE ===\")\n",
    "print(f\"Rows: {len(gold)}\")\n",
    "print(f\"Columns ({len(gold.columns)}): {list(gold.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview Gold table\n",
    "print(\"=== GOLD TABLE PREVIEW ===\")\n",
    "print(gold.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Gold\n",
    "gold.to_csv(f\"{GOLD}/gold_joined.csv\", index=False)\n",
    "\n",
    "print(f\"✓ Saved to: gold/gold_joined.csv\")\n",
    "print(f\"\\nGold table ready for Power BI!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MEDALLION PIPELINE COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "Bronze Layer (Raw):\n",
    "  - customers.csv\n",
    "  - orders.csv\n",
    "  - payments.csv\n",
    "  - support_tickets.csv\n",
    "  - web_activities.csv\n",
    "\n",
    "Silver Layer (Cleaned):\n",
    "  - customers_clean.csv\n",
    "  - orders_clean.csv\n",
    "  - payments_clean.csv\n",
    "  - support_tickets_clean.csv\n",
    "  - web_activities_clean.csv\n",
    "\n",
    "Gold Layer (Joined):\n",
    "  - gold_joined.csv (Customer 360° View)\n",
    "\n",
    "Next Steps:\n",
    "  1. Upload gold_joined.csv to Fabric Lakehouse\n",
    "  2. Create Semantic Model\n",
    "  3. Build Power BI Dashboard with 5 KPIs:\n",
    "     - Revenue by Payment Method (Pie Chart)\n",
    "     - Order Status Distribution (Bar Chart)\n",
    "     - Support Tickets by Issue Type (Bar Chart)\n",
    "     - Customer Activity by Device (Pie Chart)\n",
    "     - Revenue by City (Bar Chart / Map)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PYSPARK VERSION (For Microsoft Fabric)\n",
    "Copy the code below into a Fabric Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PYSPARK VERSION FOR FABRIC - Copy this entire cell to Fabric Notebook\n",
    "# =============================================================================\n",
    "\n",
    "pyspark_code = '''\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Configuration\n",
    "LAKEHOUSE_PATH = \"Files/\"\n",
    "BRONZE = f\"{LAKEHOUSE_PATH}bronze/\"\n",
    "SILVER = f\"{LAKEHOUSE_PATH}silver/\"\n",
    "GOLD = f\"{LAKEHOUSE_PATH}gold/\"\n",
    "\n",
    "# =============================================================================\n",
    "# BRONZE - Read Raw Data\n",
    "# =============================================================================\n",
    "df_customers_raw = spark.read.option(\"header\", \"true\").csv(f\"{BRONZE}customers.csv\")\n",
    "df_orders_raw = spark.read.option(\"header\", \"true\").csv(f\"{BRONZE}orders.csv\")\n",
    "df_payments_raw = spark.read.option(\"header\", \"true\").csv(f\"{BRONZE}payments.csv\")\n",
    "df_tickets_raw = spark.read.option(\"header\", \"true\").csv(f\"{BRONZE}support_tickets.csv\")\n",
    "df_web_raw = spark.read.option(\"header\", \"true\").csv(f\"{BRONZE}web_activities.csv\")\n",
    "\n",
    "# =============================================================================\n",
    "# SILVER - Clean Customers\n",
    "# =============================================================================\n",
    "df_customers = (\n",
    "    df_customers_raw\n",
    "    .withColumnRenamed(\"customer_id\", \"CustomerID\")\n",
    "    .withColumnRenamed(\"name\", \"Name\")\n",
    "    .withColumnRenamed(\"EMAIL\", \"Email\")\n",
    "    .withColumnRenamed(\"gender\", \"Gender\")\n",
    "    .withColumnRenamed(\"dob\", \"DOB\")\n",
    "    .withColumnRenamed(\"location\", \"City\")\n",
    "    .withColumn(\"Name\", initcap(trim(col(\"Name\"))))\n",
    "    .withColumn(\"Email\", lower(trim(col(\"Email\"))))\n",
    "    .withColumn(\"Email\", when(col(\"Email\").rlike(r\"^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,}$\"), col(\"Email\")).otherwise(lit(None)))\n",
    "    .withColumn(\"Gender\", when(lower(col(\"Gender\")).isin(\"m\", \"male\"), lit(\"Male\")).when(lower(col(\"Gender\")).isin(\"f\", \"female\"), lit(\"Female\")).otherwise(lit(None)))\n",
    "    .withColumn(\"City\", initcap(trim(col(\"City\"))))\n",
    ")\n",
    "df_customers.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"silver_customers\")\n",
    "\n",
    "# =============================================================================\n",
    "# SILVER - Clean Orders\n",
    "# =============================================================================\n",
    "df_orders = (\n",
    "    df_orders_raw\n",
    "    .withColumnRenamed(\"order_id\", \"OrderID\")\n",
    "    .withColumnRenamed(\"customer_id\", \"CustomerID\")\n",
    "    .withColumnRenamed(\"order_date\", \"OrderDate\")\n",
    "    .withColumnRenamed(\"amount\", \"OrderAmount\")\n",
    "    .withColumnRenamed(\"status\", \"OrderStatus\")\n",
    "    .withColumn(\"OrderDate\", coalesce(\n",
    "        to_date(col(\"OrderDate\"), \"yyyy-MM-dd\"),\n",
    "        to_date(col(\"OrderDate\"), \"yyyy/MM/dd\"),\n",
    "        to_date(col(\"OrderDate\"), \"dd-MM-yyyy\"),\n",
    "        to_date(col(\"OrderDate\"), \"dd/MM/yyyy\"),\n",
    "        to_date(col(\"OrderDate\"), \"yyyyMMdd\")\n",
    "    ))\n",
    "    .withColumn(\"OrderAmount\", col(\"OrderAmount\").cast(DoubleType()))\n",
    "    .fillna({\"OrderAmount\": 0.0})\n",
    "    .withColumn(\"OrderStatus\", initcap(trim(col(\"OrderStatus\"))))\n",
    ")\n",
    "df_orders.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"silver_orders\")\n",
    "\n",
    "# =============================================================================\n",
    "# SILVER - Clean Payments\n",
    "# =============================================================================\n",
    "df_payments = (\n",
    "    df_payments_raw\n",
    "    .withColumnRenamed(\"payment_id\", \"PaymentID\")\n",
    "    .withColumnRenamed(\"customer_id\", \"CustomerID\")\n",
    "    .withColumnRenamed(\"payment_date\", \"PaymentDate\")\n",
    "    .withColumnRenamed(\"payment_method\", \"PaymentMethod\")\n",
    "    .withColumnRenamed(\"payment_status\", \"PaymentStatus\")\n",
    "    .withColumnRenamed(\"amount\", \"PaymentAmount\")\n",
    "    .withColumn(\"PaymentDate\", coalesce(\n",
    "        to_date(col(\"PaymentDate\"), \"yyyy-MM-dd\"),\n",
    "        to_date(col(\"PaymentDate\"), \"yyyy/MM/dd\"),\n",
    "        to_date(col(\"PaymentDate\"), \"dd-MM-yyyy\"),\n",
    "        to_date(col(\"PaymentDate\"), \"yyyyMMdd\")\n",
    "    ))\n",
    "    .withColumn(\"PaymentMethod\", when(lower(col(\"PaymentMethod\")).isin(\"creditcard\", \"credit card\"), lit(\"Credit Card\")).otherwise(initcap(trim(col(\"PaymentMethod\")))))\n",
    "    .withColumn(\"PaymentStatus\", initcap(trim(col(\"PaymentStatus\"))))\n",
    "    .withColumn(\"PaymentAmount\", col(\"PaymentAmount\").cast(DoubleType()))\n",
    "    .fillna({\"PaymentAmount\": 0.0})\n",
    ")\n",
    "df_payments.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"silver_payments\")\n",
    "\n",
    "# =============================================================================\n",
    "# SILVER - Clean Support Tickets\n",
    "# =============================================================================\n",
    "df_tickets = (\n",
    "    df_tickets_raw\n",
    "    .withColumnRenamed(\"ticket_id\", \"TicketID\")\n",
    "    .withColumnRenamed(\"customer_id\", \"CustomerID\")\n",
    "    .withColumnRenamed(\"issue_type\", \"IssueType\")\n",
    "    .withColumnRenamed(\"ticket_date\", \"TicketDate\")\n",
    "    .withColumnRenamed(\"resolution_status\", \"ResolutionStatus\")\n",
    "    .withColumn(\"TicketDate\", coalesce(\n",
    "        to_date(col(\"TicketDate\"), \"yyyy-MM-dd\"),\n",
    "        to_date(col(\"TicketDate\"), \"yyyy/MM/dd\"),\n",
    "        to_date(col(\"TicketDate\"), \"dd-MM-yyyy\"),\n",
    "        to_date(col(\"TicketDate\"), \"yyyyMMdd\")\n",
    "    ))\n",
    "    .withColumn(\"IssueType\", initcap(trim(col(\"IssueType\"))))\n",
    "    .withColumn(\"ResolutionStatus\", initcap(trim(col(\"ResolutionStatus\"))))\n",
    ")\n",
    "df_tickets.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"silver_tickets\")\n",
    "\n",
    "# =============================================================================\n",
    "# SILVER - Clean Web Activities\n",
    "# =============================================================================\n",
    "df_web = (\n",
    "    df_web_raw\n",
    "    .withColumnRenamed(\"session_id\", \"SessionID\")\n",
    "    .withColumnRenamed(\"customer_id\", \"CustomerID\")\n",
    "    .withColumnRenamed(\"page_viewed\", \"PageViewed\")\n",
    "    .withColumnRenamed(\"session_time\", \"SessionTime\")\n",
    "    .withColumnRenamed(\"device_type\", \"DeviceType\")\n",
    "    .withColumn(\"SessionTime\", coalesce(\n",
    "        to_date(col(\"SessionTime\"), \"yyyy-MM-dd\"),\n",
    "        to_date(col(\"SessionTime\"), \"yyyy/MM/dd\"),\n",
    "        to_date(col(\"SessionTime\"), \"dd-MM-yyyy\"),\n",
    "        to_date(col(\"SessionTime\"), \"yyyyMMdd\")\n",
    "    ))\n",
    "    .withColumn(\"PageViewed\", lower(trim(col(\"PageViewed\"))))\n",
    "    .withColumn(\"DeviceType\", initcap(trim(col(\"DeviceType\"))))\n",
    ")\n",
    "df_web.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"silver_web\")\n",
    "\n",
    "# =============================================================================\n",
    "# GOLD - Join All Tables\n",
    "# =============================================================================\n",
    "customers = spark.table(\"silver_customers\").alias(\"c\")\n",
    "orders = spark.table(\"silver_orders\").alias(\"o\")\n",
    "payments = spark.table(\"silver_payments\").alias(\"p\")\n",
    "tickets = spark.table(\"silver_tickets\").alias(\"t\")\n",
    "web = spark.table(\"silver_web\").alias(\"w\")\n",
    "\n",
    "gold = (\n",
    "    customers\n",
    "    .join(orders, col(\"c.CustomerID\") == col(\"o.CustomerID\"), \"left\")\n",
    "    .join(payments, col(\"c.CustomerID\") == col(\"p.CustomerID\"), \"left\")\n",
    "    .join(tickets, col(\"c.CustomerID\") == col(\"t.CustomerID\"), \"left\")\n",
    "    .join(web, col(\"c.CustomerID\") == col(\"w.CustomerID\"), \"left\")\n",
    "    .select(\n",
    "        col(\"c.CustomerID\"), col(\"c.Name\"), col(\"c.Email\"), col(\"c.Gender\"), col(\"c.DOB\"), col(\"c.City\"),\n",
    "        col(\"o.OrderID\"), col(\"o.OrderDate\"), col(\"o.OrderAmount\"), col(\"o.OrderStatus\"),\n",
    "        col(\"p.PaymentID\"), col(\"p.PaymentDate\"), col(\"p.PaymentMethod\"), col(\"p.PaymentStatus\"), col(\"p.PaymentAmount\"),\n",
    "        col(\"t.TicketID\"), col(\"t.IssueType\"), col(\"t.TicketDate\"), col(\"t.ResolutionStatus\"),\n",
    "        col(\"w.SessionID\"), col(\"w.PageViewed\"), col(\"w.SessionTime\"), col(\"w.DeviceType\")\n",
    "    )\n",
    ")\n",
    "\n",
    "gold.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"gold_customer_360\")\n",
    "print(\"Pipeline Complete! Gold table: gold_customer_360\")\n",
    "'''\n",
    "\n",
    "print(\"PySpark code for Fabric is stored in variable: pyspark_code\")\n",
    "print(\"Copy and paste into a Fabric Notebook to run.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
